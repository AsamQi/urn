---
title: Version 0.5.1 released
date: 2017-08-27 22:24:00
---

We've just released another Urn update - 0.5.1. This is a relatively small update, mostly composed of bug fixes and
performance improvements. That's not to say there aren't some useful new features though!

## REPL improvements
The Urn REPL is a great tool for testing and prototyping code. It's something we regularly use, and so are always eager
to improve it.

One task we often find ourselves doing is loading up the REPL, importing a module and testing a small feature in
it. This process has now been streamlined: when using the `--repl` flag, any file provided on the command line will be
automatically imported into the current scope.

We've also added a `:view` command, which allows you to preview a symbol's definition. This saves you switching between
source code and the REPL, trying to remember how you got that awesome feature to work.

![Shows the result of :view command]({{ site.baseurl }}/images/posts/2017-08-27-version-0.5.1-view.png)

## Optimised optimiser
The Urn compiler has never been the fastest beast, with the optimiser being the worst offender. Whilst the optimiser is
great at reducing the size (and speed) of generated code, it also takes considerable time to run. Even worse, much of
the optimiser's time was just spent in iterating over every node - not even running the various passes! Something had to
be done.

Urn 0.5.1 introduces a new framework for optimisations, doing something so obvious I'm surprised we weren't doing it
from the start. Instead of running each pass sequentially, we have one unified visitor object which will call each pass
for every node it hits. Not only does this substantially reduce the visitor overhead, it reduces the number of times we
have to run a pass, resulting it in an even bigger performance increase! We've also made some improvements to definition
and usage tracking, which ensures that the information is more up-to-date, and so the optimiser can make smarter
decisions.

These various improvements have resulted in a 2-3x performance increase in the optimiser (depending on Lua version and
implementation). In fact, it now takes less time to optimise the compiler than it does to load it. There is evidently
room for performance improvements elsewhere!
